{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4990cf-4f5d-41a1-8428-b9cdeac771a4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d21000-db33-4253-96f1-47d2b3cef9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "PROJECT_NAME = \"Intel-Classification-V3\"\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf0aa8-e22f-425b-8b25-eb3e055827bb",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a52c9d00-b9cb-4b16-bf18-da5a92913980",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_data = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c1da29-81a7-4d13-a372-ec96bddf44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/buildings/0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34954081-06a5-4d7d-90bb-a155d29af5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pil_image = Image.fromarray(img)\n",
    "# transformation_data(img_pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1801ba0-aebf-490f-850f-221825312417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0ea764-a2f0-42b9-8d62-247869f78782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(data_dir=\"./data/\"):\n",
    "    labels = {}\n",
    "    labels_r = {}\n",
    "    idx = -1\n",
    "    data = []\n",
    "    for label in os.listdir(data_dir):\n",
    "        idx += 1\n",
    "        labels[label] = idx\n",
    "        labels_r[idx] = label\n",
    "    for directory in tqdm(os.listdir(data_dir)):\n",
    "        for file_dir in os.listdir(data_dir + directory):\n",
    "            img = cv2.imread(data_dir + directory + \"/\" + file_dir)\n",
    "            img = cv2.resize(img,(56,56))\n",
    "            data.append([np.array(transformation_data(Image.fromarray(img))),np.eye(labels[directory]+1,idx+1)[-1]])\n",
    "    np.random.shuffle(data)\n",
    "    data = data[:5000]\n",
    "    X = []\n",
    "    y = []\n",
    "    for d_iter in data:\n",
    "        X.append(d_iter[0])\n",
    "        y.append(d_iter[1])\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,shuffle=True)\n",
    "    X_train = torch.from_numpy(np.array(X_train)).to(device)\n",
    "    y_train = torch.from_numpy(np.array(y_train)).to(device)\n",
    "    X_test = torch.from_numpy(np.array(X_test)).to(device)\n",
    "    y_test = torch.from_numpy(np.array(y_test)).to(device)\n",
    "    return labels,labels_r,data,X,y,X_train,X_test,y_train,y_test,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f650e25-82c2-4438-b19c-a6b60ebf5031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 6/6 [00:06<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "labels,labels_r,data,X,y,X_train,X_test,y_train,y_test,idx = load_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872329fb-56bf-4ae8-9653-c234b597dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(labels,'./save/labels.pt')\n",
    "torch.save(labels,'./save/labels.pth')\n",
    "torch.save(labels_r,'./save/labels_r.pt')\n",
    "torch.save(labels_r,'./save/labels_r.pth')\n",
    "torch.save(data,'./save/data.pt')\n",
    "torch.save(data,'./save/data.pth')\n",
    "torch.save(X,'./save/X.pt')\n",
    "torch.save(y,'./save/y.pth')\n",
    "torch.save(X_train,'./save/X_train.pt')\n",
    "torch.save(X_test,'./save/X_test.pth')\n",
    "torch.save(y_train,'./save/y_train.pt')\n",
    "torch.save(y_test,'./save/y_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6497dc94-0953-487e-a11a-f128d932b4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750, 1250, 3750, 1250)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_test),len(y_train),len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0d94df-460a-4dca-9fa9-b9536bf5b8ec",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cd500a2-378c-466d-b3ce-0184c987baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "271a6f3d-680c-456b-8fc9-f79338db4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,X,y):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    preds = model(X)\n",
    "    for y_iter,pred in zip(y,preds):\n",
    "        y_iter = torch.argmax(y_iter)\n",
    "        pred = torch.argmax(pred)\n",
    "        if pred == y_iter:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return round(correct/total,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96104a1f-5d02-4be2-a8ff-b83e92328e1c",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36f7b572-70d4-451f-a89c-a4481f27558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38e38b90-555c-43b1-8581-67860c6aa82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,5)\n",
    "        self.conv2 = nn.Conv2d(32,64,5)\n",
    "        self.conv2batchnorm = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64,128,5)\n",
    "        self.fc1 = nn.Linear(128*3*3,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,6)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = F.max_pool2d(self.relu(self.conv1(X)),(2,2))\n",
    "        preds = F.max_pool2d(self.relu(self.conv2batchnorm(self.conv2(preds))),(2,2))\n",
    "        preds = F.max_pool2d(self.relu(self.conv3(preds)),(2,2))\n",
    "        print(preds.shape)\n",
    "        preds = preds.view(-1,128*3*3)\n",
    "        preds = self.relu(self.fc1(preds))\n",
    "        preds = self.relu(self.fc2(preds))\n",
    "        preds = self.relu(self.fc3(preds))\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae83a0d0-260c-4ea1-8df7-3353f3328fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "868aa481-c31e-4d99-a235-19b0489a4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b2b06-9d4b-42ca-aeca-48d0ca4fd69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:764i7ih5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6353d6722a4d44869ee10c554ca1b981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name=\"BaseLine\")\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for idx in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[idx:idx+batch_size].view(-1,3,56,56).to(device)\n",
    "        y_batch = y_train[idx:idx+batch_size].to(device)\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        loss.backward()\n",
    "        wandb.log({\n",
    "            \"Test Loss\":get_loss(model,X_test,y_test),\n",
    "            \"Test Accuracy\":get_accuracy(model,X_test,y_test),\n",
    "            \"Accuracy\":get_accuracy(model,X_batch,y_batch),\n",
    "            \"Loss\":get_loss(model,X_batch,y_batch)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273cd09-1c45-4c8d-9a86-6e8281eb073a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
